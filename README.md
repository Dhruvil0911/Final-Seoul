# Seasoul Skin Analyzer â€“ Modular FastAPI Backend

A production-grade, fully modular FastAPI backend that analyzes facial skin images using **GPTâ€‘4o** and **Gemini 2.0 Flash**, merges their outputs intelligently, and returns a final consolidated structured JSON.

---

## ğŸš€ Features

* Dualâ€‘LLM image analysis (GPTâ€‘4o + Gemini 2.0 Flash)
* Confidenceâ€‘based output synthesis
* Smart primary/secondary/tertiary concern resolution
* Duplicate issues autoâ€‘removed from final metrics
* Weighted numeric merging
* Modular directory structure
* Clean Optionâ€‘B ordered response
* Fully typed, commented, productionâ€‘ready code
* Singleâ€‘model fallback handling

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ app.py                    # Main FastAPI entry
â”‚
â”œâ”€â”€ config.py                # Env keys + global config
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ prompts.py           # GPT + Gemini prompts
â”‚   â””â”€â”€ synthesizer.py       # Merging + conflict resolution logic
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ image_encoder.py     # Image â†’ Base64
â”‚   â”œâ”€â”€ llm_runner.py        # Runs both LLMs in parallel
â”‚   â”œâ”€â”€ openai_client.py     # GPTâ€‘4o API wrapper
â”‚   â””â”€â”€ gemini_client.py     # Gemini SDK/REST wrapper
â”‚
â””â”€â”€ requirements.txt         # Dependencies
```

---

## ğŸ§  How It Works

### **1. /analyze-skin endpoint:**

* Upload image
* Convert to base64
* Run GPTâ€‘4o & Gemini in parallel
* Parse output JSON
* If both fail â†’ return error
* If one succeeds â†’ finalize that one
* If both succeed â†’ merge via synthesizer

### **2. Synthesizer Logic:**

* Load both model outputs
* Choose higher-confidence model
* Extract primary/secondary/tertiary (top 3 severity)
* Merge attributes (weighted average / string confidence)
* Drop duplicated concerns from metric list
* Apply final ordered output

---

## ğŸ”§ Installation

```bash
pip install -r requirements.txt
```

---

## â–¶ Run the Server

### Development mode:

```bash
uvicorn app:app --reload
```

### Production (recommended):

```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

---

## ğŸ”‘ Environment Variables

You must set:

```
OPENAI_API_KEY="your-key"
GOOGLE_API_KEY="your-key"
```

In Linux/macOS:

```bash
export OPENAI_API_KEY="..."
export GOOGLE_API_KEY="..."
```

Windows:

```cmd
set OPENAI_API_KEY=...
set GOOGLE_API_KEY=...
```

---

## ğŸ§ª API Example

### Upload image:

```
POST /analyze-skin
Content-Type: multipart/form-data
file: <image>
```

### Response Structure (Option B ordering):

```
{
  "perceived_skin_age": 45,
  "skin_type": "Normal",
  "skin_type_score": 3,

  "primary_concern": "wrinkles",
  "primary_concern_severity": 3,
  "secondary_concern": "spots",
  "secondary_concern_severity": 3,
  "tertiary_concern": "texture",
  "tertiary_concern_severity": 2,

  "oiliness": 2,
  "pores": 2,
  "dehydration": 1,
  "elasticity": 3,
  ... etc
}
```

---

## ğŸ›  Deployment Tips

* Use `uvicorn` or `gunicorn` with workers
* Keep API keys in environment, not hardcoded
* Enable CORS for your frontend domain
* Use Reverse Proxy (NGINX) for SSL + routing

---

---

## ğŸ§‘â€ğŸ’» Author

**Dhruvil Bhaliya**

Modularization, patch cleanup & enhancements by ChatGPT.


